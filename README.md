

## Otimiza√ß√£o do Spark

Aqui est√£o algumas dicas para otimizar o Spark e economizar recursos:

### 1. Otimize o Shuffle Partitions
O par√¢metro `spark.sql.shuffle.partitions` controla o n√∫mero de parti√ß√µes usadas durante as trocas de dados (joins e agrega√ß√µes). A recomenda√ß√£o √© manter cada parti√ß√£o entre 100 MB e 200 MB.

| Tamanho Total dos Dados | `spark.sql.shuffle.partitions` | Justificativa |
| :--- | :--- | :--- |
| **Pequeno** (< 1 GB) | 10 a 50 | Evita o overhead de muitas tarefas pequenas. |
| **M√©dio** (1 GB a 10 GB) | 50 a 200 | Mant√©m o paralelismo alinhado com executores m√©dios. |
| **Grande** (10 GB a 100 GB) | 200 a 1000 | Evita sobrecarga no Garbage Collection (GC). |
| **Muito Grande** (> 100 GB) | 1000+ | Necess√°rio para distribuir carga em clusters massivos. |

Rela√ß√£o com o maxPartitionBytes

Enquanto o spark.sql.shuffle.partitions controla os dados durante as trocas (joins/agregados), o seu guia menciona o spark.sql.files.maxPartitionBytes. Este √∫ltimo controla a leitura inicial do disco.

    Se voc√™ ler 10 GB de dados com maxPartitionBytes em 128 MB, ter√° inicialmente cerca de 80 parti√ß√µes.

    Se voc√™ n√£o ajustar o shuffle, o Spark usar√° o padr√£o de 200, o que pode ser excessivo para esse volume, gerando tarefas vazias.

Dica Extra: Sempre monitore a aba SQL no Spark UI. Se voc√™ notar que o "Shuffle Read Size" por tarefa est√° muito alto (ex: > 500 MB), aumente o n√∫mero de parti√ß√µes para evitar o uso excessivo de mem√≥ria do executor (spark.executor.memory).

> **Dica:** No Spark 3.0+, habilite o AQE (`spark.sql.adaptive.enabled`) para que o Spark ajuste esse n√∫mero automaticamente.

### 2. Ajuste o tamanho dos blocos (block size)
O par√¢metro `spark.sql.files.maxPartitionBytes` define o tamanho m√°ximo dos blocos lidos do disco, ajudando a reduzir o n√∫mero de tarefas iniciais.

| Tamanho do arquivo | spark.sql.files.maxPartitionBytes | spark.sql.files.openCostInBytes |
| :--- | :--- | :--- |
| **Pequeno** (< 100 MB) | 32 MB a 64 MB | 1 MB a 4 MB |
| **M√©dio** (100 MB a 1 GB) | 64 MB a 128 MB | 4 MB a 16 MB |
| **Grande** (1 GB a 10 GB) | 128 MB a 256 MB | 16 MB a 64 MB |
| **Muito grande** (> 10 GB) | 256 MB a 512 MB | 64 MB a 128 MB |

* **Regra geral:** O tamanho dos blocos deve ser entre 1/10 e 1/5 do tamanho do arquivo.
* **Custo de abertura:** Deve ser entre 1/100 e 1/50 do tamanho do bloco.


### 3. Use o cache de dados
* Use `spark.cache` para armazenar dados acessados frequentemente em mem√≥ria.
* Utilize `cache()` ou `persist()` para evitar reprocessamento e reduzir leitura de disco.

### 4. Otimize as jun√ß√µes (joins)
O **broadcast** envia tabelas pequenas para todos os n√≥s, permitindo jun√ß√µes locais sem shuffle.

| Categoria da Tabela | Tamanho | Ajuste do `spark.sql.autoBroadcastJoinThreshold` |
| :--- | :--- | :--- |
| **Pequena** | < 10 MB | Transmitida automaticamente (padr√£o). |
| **M√©dia** | 10 MB a 100 MB | Aumente para 50 MB ou 100 MB. |
| **Grande** | > 100 MB | Geralmente n√£o √© transmitida automaticamente. |

### 5. Ajuste o paralelismo e mem√≥ria
Ajuste o `spark.default.parallelism` e a mem√≥ria do executor para evitar falhas e lentid√£o no processamento.

| Tamanho dos dados | spark.default.parallelism | spark.executor.memory |
| :--- | :--- | :--- |
| **Pequeno** (< 100 MB) | 2-4 | 1-2 GB |
| **M√©dio** (100 MB a 1 GB) | 4-8 | 2-4 GB |
| **Grande** (1 GB a 10 GB) | 8-16 | 4-8 GB |
| **Muito grande** (> 10 GB) | 16-32 | 8-16 GB |

#### Configura√ß√µes de RAM do Executor:
* `spark.executor.memoryOverhead`: Mem√≥ria para o SO e processos externos.
* `spark.memory.fraction`: Fra√ß√£o da RAM para armazenamento (padr√£o 0.6).
* `spark.memory.storageFraction`: Fra√ß√£o da RAM para cache (padr√£o 0.5).

### 6. Use o Spark SQL
O Spark SQL (DataFrames e Datasets) √© mais eficiente que a RDD API devido ao otimizador Catalyst.

---
Lembre-se de monitorar o desempenho do seu aplicativo Spark e ajustar as configura√ß√µes conforme necess√°rio! üòä
